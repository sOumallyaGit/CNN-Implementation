{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5127aa6e-e7c5-4ef0-b49e-c2efa689a34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88558cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b67321",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c477d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Data Preprocessing\n",
    "## Training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    'training_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89686d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "## Test Set\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_datagen.flow_from_directory(\n",
    "    'test_set',\n",
    "    target_size=(64,64),\n",
    "    batch_size=32,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63f055e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialising the CNN \n",
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a73d809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "## Convolution\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11958cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3917e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2nd Convolutional Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed63e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a6f1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=32,activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d7cbaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcbb8efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compiling the Model\n",
    "cnn.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa705655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 42ms/step - accuracy: 0.5500 - loss: 0.6861 - val_accuracy: 0.6610 - val_loss: 0.6189\n",
      "Epoch 2/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.6555 - loss: 0.6226 - val_accuracy: 0.6955 - val_loss: 0.5862\n",
      "Epoch 3/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.6975 - loss: 0.5851 - val_accuracy: 0.6160 - val_loss: 0.6698\n",
      "Epoch 4/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.7153 - loss: 0.5571 - val_accuracy: 0.7470 - val_loss: 0.5310\n",
      "Epoch 5/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 40ms/step - accuracy: 0.7368 - loss: 0.5271 - val_accuracy: 0.7605 - val_loss: 0.5086\n",
      "Epoch 6/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.7489 - loss: 0.5078 - val_accuracy: 0.7310 - val_loss: 0.5410\n",
      "Epoch 7/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7558 - loss: 0.5018 - val_accuracy: 0.7685 - val_loss: 0.4895\n",
      "Epoch 8/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.7569 - loss: 0.4962 - val_accuracy: 0.7760 - val_loss: 0.4840\n",
      "Epoch 9/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7804 - loss: 0.4659 - val_accuracy: 0.7800 - val_loss: 0.4787\n",
      "Epoch 10/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.7767 - loss: 0.4631 - val_accuracy: 0.7700 - val_loss: 0.4728\n",
      "Epoch 11/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.7754 - loss: 0.4669 - val_accuracy: 0.7875 - val_loss: 0.4636\n",
      "Epoch 12/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.7767 - loss: 0.4506 - val_accuracy: 0.7975 - val_loss: 0.4435\n",
      "Epoch 13/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.7965 - loss: 0.4316 - val_accuracy: 0.7955 - val_loss: 0.4430\n",
      "Epoch 14/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 41ms/step - accuracy: 0.8026 - loss: 0.4270 - val_accuracy: 0.8130 - val_loss: 0.4356\n",
      "Epoch 15/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8066 - loss: 0.4195 - val_accuracy: 0.7870 - val_loss: 0.4769\n",
      "Epoch 16/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - accuracy: 0.8112 - loss: 0.4144 - val_accuracy: 0.7965 - val_loss: 0.4556\n",
      "Epoch 17/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 34ms/step - accuracy: 0.8121 - loss: 0.4105 - val_accuracy: 0.8125 - val_loss: 0.4271\n",
      "Epoch 18/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8195 - loss: 0.3947 - val_accuracy: 0.8130 - val_loss: 0.4314\n",
      "Epoch 19/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8260 - loss: 0.3821 - val_accuracy: 0.8035 - val_loss: 0.4461\n",
      "Epoch 20/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.8291 - loss: 0.3833 - val_accuracy: 0.7910 - val_loss: 0.4599\n",
      "Epoch 21/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8301 - loss: 0.3767 - val_accuracy: 0.8150 - val_loss: 0.4372\n",
      "Epoch 22/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8297 - loss: 0.3675 - val_accuracy: 0.8105 - val_loss: 0.4345\n",
      "Epoch 23/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 43ms/step - accuracy: 0.8375 - loss: 0.3633 - val_accuracy: 0.8100 - val_loss: 0.4300\n",
      "Epoch 24/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 37ms/step - accuracy: 0.8376 - loss: 0.3661 - val_accuracy: 0.7760 - val_loss: 0.5399\n",
      "Epoch 25/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8349 - loss: 0.3632 - val_accuracy: 0.8095 - val_loss: 0.4570\n",
      "Epoch 26/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 38ms/step - accuracy: 0.8469 - loss: 0.3380 - val_accuracy: 0.8035 - val_loss: 0.4301\n",
      "Epoch 27/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 37ms/step - accuracy: 0.8570 - loss: 0.3308 - val_accuracy: 0.8105 - val_loss: 0.4400\n",
      "Epoch 28/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 36ms/step - accuracy: 0.8464 - loss: 0.3388 - val_accuracy: 0.7920 - val_loss: 0.4849\n",
      "Epoch 29/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 39ms/step - accuracy: 0.8432 - loss: 0.3469 - val_accuracy: 0.8105 - val_loss: 0.4635\n",
      "Epoch 30/30\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 35ms/step - accuracy: 0.8598 - loss: 0.3133 - val_accuracy: 0.7920 - val_loss: 0.5510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x137dd4cb0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Training CNN on the Training set and evaluating it on the test set\n",
    "cnn.fit(x=training_set , validation_data=test_set,epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5df9f40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "Class indices: {'cats': 0, 'dogs': 1}\n",
      "Predicted class: cats\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "\n",
    "test_image = image.load_img('cat test data.jpeg', target_size=(64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis=0)\n",
    "\n",
    "\n",
    "result = cnn.predict(test_image)\n",
    "\n",
    "\n",
    "class_indices = training_set.class_indices\n",
    "print(\"Class indices:\", class_indices)\n",
    "\n",
    "\n",
    "predicted_class = np.argmax(result, axis=1)\n",
    "\n",
    "\n",
    "for class_label, index in class_indices.items():\n",
    "    if index == predicted_class:\n",
    "        prediction = class_label\n",
    "        break\n",
    "\n",
    "\n",
    "print(\"Predicted class:\", prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "59af701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474183c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
